{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#importing the libraries\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import json\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Flatten\n","from tensorflow.keras.models import Model\n","import matplotlib.pyplot as plt\n","import joblib\n","import os\n","\n","res = json.load(open('covid_responses.json'))\n","\n","file = pd.read_csv('data.csv')\n","data = file[['inputs', 'tags']]\n","data = data.sample(frac=1)\n","\n","\n","file = pd.read_csv('data.csv')\n","data = file[['inputs', 'tags']]\n","data = data.sample(frac=1)\n","\n","\n","import string\n","data['inputs'] = data['inputs'].apply(lambda wrd:[ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n","data['inputs'] = data['inputs'].apply(lambda wrd: ''.join(wrd))\n","\n","#tokenize the data\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","tokenizer = Tokenizer(num_words=2000)\n","tokenizer.fit_on_texts(data['inputs'])\n","train = tokenizer.texts_to_sequences(data['inputs'])\n","#apply padding\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","x_train = pad_sequences(train)\n","\n","#encoding the outputs\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","y_train = le.fit_transform(data['tags'])\n","input_shape = x_train.shape[1]\n","\n","\n","vocabulary = len(tokenizer.word_index)\n","output_length = le.classes_.shape[0]\n","\n","def create_model():\n","    i = Input(shape=(18,))\n","    x = Embedding(788+1,10)(i)\n","    x = LSTM(10,return_sequences=True)(x)\n","    x = Flatten()(x)\n","    x = Dense(output_length,activation=\"softmax\")(x)\n","    model  = Model(i,x)\n","    model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])\n","    \n","    return model\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["array([[  0,   0,   0, ...,   4,   2, 225],\n","       [  0,   0,   0, ..., 226,   9,  82],\n","       [  0,   0,   0, ...,   1,   4,   2],\n","       ...,\n","       [  0,   0,   0, ...,  40,   1,   2],\n","       [  0,   0,   0, ..., 788,  12,   7],\n","       [  0,   0,   0, ...,  72,   1,   2]])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["x_train"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## save method 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create and train a new model instance.\n","model = create_model()\n","model.fit(x_train, y_train, epochs=200)\n","\n","# Save the entire model as a SavedModel.\n","!mkdir -p saved_model\n","model.save('saved_model/my_model')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_model = tf.keras.models.load_model('saved_model/my_model')\n","\n","# Check its architecture\n","new_model.summary()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## save method 2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = create_model()\n","\n","checkpoint_path = \"training_1/cp.ckpt\"\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","# Create a callback that saves the model's weights\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 verbose=1)\n","\n","# Train the model with the new callback\n","model.fit(x_train, \n","          y_train,  \n","          epochs=200,\n","          callbacks=[cp_callback])  # Pass callback to training\n","\n","# This may generate warnings related to saving the state of the optimizer.\n","# These warnings (and similar warnings throughout this notebook)\n","# are in place to discourage outdated usage, and can be ignored."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x148ff64eee0>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["model1 = create_model()\n","model1.load_weights(\"training_1/cp.ckpt\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## save method 3"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Include the epoch in the file name (uses `str.format`)\n","import os\n","checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","batch_size = 32\n","\n","# Create a callback that saves the model's weights every 5 epochs\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_path, \n","    verbose=1, \n","    save_weights_only=True,\n","    save_freq=5*batch_size)\n","\n","# Create a new model instance\n","model = create_model()\n","\n","# Save the weights using the `checkpoint_path` format\n","model.save_weights(checkpoint_path.format(epoch=0))\n","\n","# Train the model with the new callback\n","model.fit(train_images, \n","          train_labels,\n","          epochs=50, \n","          batch_size=batch_size, \n","          callbacks=[cp_callback],\n","          validation_data=(test_images, test_labels),\n","          verbose=0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# checking responses of COVID chatbot"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def model_output(prediction_input):\n","  import random\n","  #removing punctuation and converting to lowercase\n","  prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]\n","  prediction_input = ''.join(prediction_input)\n","  texts_p = []\n","  texts_p.append(prediction_input)\n","\n","  #tokenizing and padding\n","  prediction_input = tokenizer.texts_to_sequences(texts_p)\n","  prediction_input = np.array(prediction_input).reshape(-1)\n","  prediction_input = pad_sequences([prediction_input],18)\n","\n","  #getting output from model\n","  output = model1.predict(prediction_input)\n","  output = output.argmax()\n","\n","  #finding the right tag and predicting\n","  response_tag = le.inverse_transform([output])[0]\n","  final_response = str(random.choice(res[response_tag]))\n","\n","  return final_response"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Chatbot: The symptoms of COVID-19 are very similar to symptoms of other illnesses, such as colds and flu. Most people feel better within a few days or weeks of their first COVID-19 symptoms and make a full recovery within 12 weeks. For some people, it can be a more serious illness and their symptoms can last longer. While we are still learning about how COVID-2019 affects people, older persons and persons with pre-existing medical conditions (such as high blood pressure, heart disease, lung disease, cancer or diabetes) appear to develop serious illness more often than others.\n"]}],"source":["input = 'covid positive'\n","model_testing = model_output(input)\n","print('Chatbot: ' + model_testing)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":557},"executionInfo":{"elapsed":54778,"status":"error","timestamp":1681120163681,"user":{"displayName":"Mirza Waleed","userId":"15090822999105960142"},"user_tz":-480},"id":"u6hBq4ZI9Vbh","outputId":"ccd738c8-3f61-4557-dc1e-cfb8145729a8"},"outputs":[],"source":["#chatting\n","import random\n","\n","\n","while True:\n","  texts_p = []\n","  prediction_input = input('You : ')\n","\n","  #removing punctuation and converting to lowercase\n","  prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]\n","  prediction_input = ''.join(prediction_input)\n","  texts_p.append(prediction_input)\n","\n","  #tokenizing and padding\n","  prediction_input = tokenizer.texts_to_sequences(texts_p)\n","  prediction_input = np.array(prediction_input).reshape(-1)\n","  prediction_input = pad_sequences([prediction_input],input_shape)\n","\n","  #getting output from model\n","  output = model.predict(prediction_input)\n","  output = output.argmax()\n","\n","  #finding the right tag and predicting\n","  response_tag = le.inverse_transform([output])[0]\n","  print(\"Chatbot : \",random.choice(res[response_tag]))\n","  if response_tag == \"goodbye\":\n","    break"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
